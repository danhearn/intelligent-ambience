# LLM Provider Configuration
# Options: ollama, openai, anthropic
LLM_PROVIDER=ollama

# Ollama Configuration (if using Ollama)
OLLAMA_BASE_URL=http://localhost:11434

# OpenAI Configuration (if using OpenAI)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Configuration (if using Anthropic)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Other Configuration
PYTHONUNBUFFERED=1
CUDA_VISIBLE_DEVICES=0
